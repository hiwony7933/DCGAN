{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitanaconda3condae788c5fa592f4db3927eca9f2fe371f6",
   "display_name": "Python 3.7.4 64-bit ('anaconda3': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.models import * \n",
    "from keras.layers import * \n",
    "from keras.optimizers import * \n",
    "from keras.datasets import mnist \n",
    "import keras.backend as K \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "K.set_image_data_format('channels_last') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gan: \n",
    "    def __init__(self, img_data): \n",
    "        img_size = img_data.shape[1] \n",
    "        channel = img_data.shape[3] if len(img_data.shape) >= 4 else 1 \n",
    "        self.img_data = img_data \n",
    "        self.input_shape = (img_size, img_size, channel) \n",
    "        self.img_rows = img_size \n",
    "        self.img_cols = img_size \n",
    "        self.channel = channel \n",
    "        self.noise_size = 100 \n",
    "        \n",
    "        self.create_d() \n",
    "        self.create_g() \n",
    "        \n",
    "        optimizer = Adam(lr=0.0008) \n",
    "        self.D.compile(loss='binary_crossentropy', optimizer=optimizer) \n",
    "        \n",
    "        optimizer = Adam(lr=0.0004) \n",
    "        self.D.trainable = False \n",
    "        self.AM = Sequential() \n",
    "        self.AM.add(self.G) \n",
    "        self.AM.add(self.D) \n",
    "        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer) \n",
    "        print('AM \\n')\n",
    "        self.AM.summary()\n",
    "        \n",
    "    def create_d(self): \n",
    "        self.D = Sequential() \n",
    "        depth = 64 \n",
    "        dropout = 0.4 \n",
    "        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=self.input_shape, padding='same')) \n",
    "        self.D.add(LeakyReLU(alpha=0.2)) \n",
    "        self.D.add(Dropout(dropout)) \n",
    "        self.D.add(Conv2D(depth*2, 5, strides=2, padding='same')) \n",
    "        self.D.add(LeakyReLU(alpha=0.2)) \n",
    "        self.D.add(Dropout(dropout)) \n",
    "        self.D.add(Conv2D(depth*4, 5, strides=2, padding='same')) \n",
    "        self.D.add(LeakyReLU(alpha=0.2)) \n",
    "        self.D.add(Dropout(dropout)) \n",
    "        self.D.add(Conv2D(depth*8, 5, strides=1, padding='same')) \n",
    "        self.D.add(LeakyReLU(alpha=0.2)) \n",
    "        self.D.add(Dropout(dropout)) \n",
    "        self.D.add(Flatten()) \n",
    "        self.D.add(Dense(1)) \n",
    "        self.D.add(Activation('sigmoid')) \n",
    "        print('Discriminator \\n')\n",
    "        self.D.summary() \n",
    "        return self.D \n",
    "        \n",
    "    def create_g(self): \n",
    "        self.G = Sequential() \n",
    "        dropout = 0.4 \n",
    "        depth = 64+64+64+64 \n",
    "        dim = 7 \n",
    "        self.G.add(Dense(dim*dim*depth, input_dim=self.noise_size)) \n",
    "        self.G.add(BatchNormalization(momentum=0.9)) \n",
    "        self.G.add(Activation('relu')) \n",
    "        self.G.add(Reshape((dim, dim, depth))) \n",
    "        self.G.add(Dropout(dropout)) \n",
    "        self.G.add(UpSampling2D()) \n",
    "        self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same')) \n",
    "        self.G.add(BatchNormalization(momentum=0.9)) \n",
    "        self.G.add(Activation('relu')) \n",
    "        self.G.add(UpSampling2D()) \n",
    "        self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same')) \n",
    "        self.G.add(BatchNormalization(momentum=0.9)) \n",
    "        self.G.add(Activation('relu')) \n",
    "        self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same')) \n",
    "        self.G.add(BatchNormalization(momentum=0.9)) \n",
    "        self.G.add(Activation('relu')) \n",
    "        self.G.add(Conv2DTranspose(1, 5, padding='same')) \n",
    "        self.G.add(Activation('sigmoid')) \n",
    "        print('Generator \\n')\n",
    "        self.G.summary() \n",
    "        return self.G \n",
    "        \n",
    "    def train(self, batch_size=100): \n",
    "        images_train = self.img_data[np.random.randint(0, self.img_data.shape[0], size=batch_size), :, :, :] \n",
    "        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, self.noise_size]) \n",
    "        images_fake = self.G.predict(noise) \n",
    "         \n",
    "        x = np.concatenate((images_train, images_fake)) \n",
    "        y = np.ones([2*batch_size, 1]) \n",
    "        y[batch_size:, :] = 0 \n",
    "        self.D.trainable = True \n",
    "        d_loss = self.D.train_on_batch(x, y) \n",
    "        \n",
    "        y = np.ones([batch_size, 1]) \n",
    "        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, self.noise_size]) \n",
    "        self.D.trainable = False \n",
    "        a_loss = self.AM.train_on_batch(noise, y) \n",
    "        return d_loss, a_loss, images_fake \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(60000, 28, 28, 1)\n"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0 \n",
    "x_train = x_train.reshape((x_train.shape[0],) + (28, 28, 1)) \n",
    "print(x_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init network \n",
    "gan = Gan(x_train) \n",
    "\n",
    "# Some parameters. \n",
    "epochs = 30 \n",
    "sample_size = 10 \n",
    "batch_size = 100 \n",
    "train_per_epoch = x_train.shape[0] // batch_size \n",
    "history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, epochs): \n",
    "    print(\"Epoch:\", epoch + 1) \n",
    "    \n",
    "    total_d_loss = 0.0 \n",
    "    total_a_loss = 0.0 \n",
    "    \n",
    "    for batch in range(0, train_per_epoch): \n",
    "        d_loss, a_loss, imgs = gan.train(batch_size) \n",
    "        total_d_loss += d_loss \n",
    "        total_a_loss += a_loss \n",
    "        \n",
    "    total_d_loss /= train_per_epoch \n",
    "    total_a_loss /= train_per_epoch \n",
    "    recode =(epoch, d_loss, a_loss)\n",
    "    history.append(recode)\n",
    "\n",
    "    print(\"D Loss: {}, AM Loss: {}\".format(total_d_loss, total_a_loss)) \n",
    "    \n",
    "    fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1)) \n",
    "    for i in range(0, sample_size): \n",
    "        ax[i].set_axis_off() \n",
    "        ax[i].imshow(imgs[i].reshape((gan.img_rows, gan.img_cols, gan.channel)), interpolation='nearest')\n",
    "    plt.show() \n",
    "    plt.close(fig)\n",
    "    gan.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd \n",
    "\n",
    "df = DataFrame(history, columns=['epoch', 'd_loss', 'g_loss'])\n",
    "\n",
    "df.plot(y=['d_loss', 'g_loss'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}